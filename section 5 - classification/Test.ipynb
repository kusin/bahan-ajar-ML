{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of iris flower using supervised learning algorthm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lib data manipulations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# lib data visualizaton\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# lib data preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# lib supervised learning\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# library evaluation model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataset = pd.read_csv(\"../dataset/iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sepal_length  sepal_width  petal_length  petal_width\n",
      "count        150.00       150.00        150.00       150.00\n",
      "mean           5.84         3.05          3.76         1.20\n",
      "std            0.83         0.43          1.76         0.76\n",
      "min            4.30         2.00          1.00         0.10\n",
      "25%            5.10         2.80          1.60         0.30\n",
      "50%            5.80         3.00          4.35         1.30\n",
      "75%            6.40         3.30          5.10         1.80\n",
      "max            7.90         4.40          6.90         2.50\n"
     ]
    }
   ],
   "source": [
    "# show metadata\n",
    "print(np.round(dataset.describe(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n"
     ]
    }
   ],
   "source": [
    "# show dataset\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features and Labels\n",
    "x = dataset[[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"]].values\n",
    "y = dataset[\"species\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split validation\n",
    "trainX, testX, trainY, testY = train_test_split(scaled, y, train_size=0.7, test_size=0.3, random_state=7, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 4) (105,)\n"
     ]
    }
   ],
   "source": [
    "# show dimension of data train\n",
    "print(trainX.shape, trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 4) (45,)\n"
     ]
    }
   ],
   "source": [
    "# show dimension of data test\n",
    "print(testX.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Modeling Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decision Tree C45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised learning algorithm\n",
    "result_C45 = DecisionTreeClassifier(criterion=\"gini\", random_state=None).fit(trainX, trainY).predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  0,  0],\n",
       "       [ 0, 12,  4],\n",
       "       [ 0,  2, 15]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation models - confusion_matrix\n",
    "conf_C45 = confusion_matrix(testY, result_C45)\n",
    "conf_C45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        12\n",
      "  versicolor       0.86      0.75      0.80        16\n",
      "   virginica       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.87        45\n",
      "   macro avg       0.88      0.88      0.88        45\n",
      "weighted avg       0.87      0.87      0.87        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluation models - classification_report\n",
    "print(classification_report(y_true=testY, y_pred=result_C45))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Naive Bayes - Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised learning algorithm\n",
    "result_gnb = GaussianNB().fit(trainX, trainY).predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  0,  0],\n",
       "       [ 0, 13,  3],\n",
       "       [ 0,  2, 15]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation models - confusion_matrix\n",
    "conf_gnb = confusion_matrix(testY, result_gnb)\n",
    "conf_gnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        12\n",
      "  versicolor       0.87      0.81      0.84        16\n",
      "   virginica       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.89        45\n",
      "   macro avg       0.90      0.90      0.90        45\n",
      "weighted avg       0.89      0.89      0.89        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluation models - classification_report\n",
    "print(classification_report(y_true=testY, y_pred=result_gnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- K Nearest-Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised learning algorithm\n",
    "result_knn = KNeighborsClassifier(n_neighbors=3).fit(trainX, trainY).predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  0,  0],\n",
       "       [ 0, 16,  0],\n",
       "       [ 0,  2, 15]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation models - confusion_matrix\n",
    "conf_knn = confusion_matrix(testY, result_knn)\n",
    "conf_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        12\n",
      "  versicolor       0.89      1.00      0.94        16\n",
      "   virginica       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.96      0.96      0.96        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluation models - classification_report\n",
    "print(classification_report(y_true=testY, y_pred=result_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised learning algorithm\n",
    "result_lr = LogisticRegression(max_iter=1000).fit(trainX, trainY).predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  0,  0],\n",
       "       [ 0, 11,  5],\n",
       "       [ 0,  2, 15]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation models - confusion_matrix\n",
    "conf_lr = confusion_matrix(testY, result_lr)\n",
    "conf_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        12\n",
      "  versicolor       0.85      0.69      0.76        16\n",
      "   virginica       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.84        45\n",
      "   macro avg       0.87      0.86      0.86        45\n",
      "weighted avg       0.85      0.84      0.84        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluation models - classification_report\n",
    "print(classification_report(y_true=testY, y_pred=result_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised learning algorithm\n",
    "result_svc = SVC(kernel='rbf').fit(trainX, trainY).predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  0,  0],\n",
       "       [ 0, 14,  2],\n",
       "       [ 0,  1, 16]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation models - confusion_matrix\n",
    "conf_svc = confusion_matrix(testY, result_svc)\n",
    "conf_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        12\n",
      "  versicolor       0.93      0.88      0.90        16\n",
      "   virginica       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.94      0.94      0.94        45\n",
      "weighted avg       0.93      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluation models - classification_report\n",
    "print(classification_report(y_true=testY, y_pred=result_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
