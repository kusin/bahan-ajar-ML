{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions of BTC-USD Price Using SBi-LSTM and SBi-GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all functions\n",
    "from C01_visualization import *\n",
    "from C02_model_predictions import *\n",
    "from C03_model_evaluate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lib manipulation data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# lib data visualizations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# lib data preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- config models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random number\n",
    "import random as rm\n",
    "rm.seed(1234)\n",
    "\n",
    "# set random number\n",
    "import numpy as np\n",
    "np.random.seed(1234)\n",
    "\n",
    "# set random number\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataset = pd.read_csv(\"../dataset/Cryptocurrency-BTC-USD-2024-04.csv\", parse_dates=['Date'])\n",
    "dataset = dataset[[\"Date\", \"Open\", \"High\", \"Low\", \"Close\"]]\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show dataset\n",
    "print(dataset.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Exploration Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_matplotlib(dataset, [\"Open\", \"High\", \"Low\", \"Close\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. process feature selection\n",
    "data = dataset.filter(['Close'])\n",
    "data = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. results feature selection\n",
    "np.round(data[:5],6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. process normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(np.array(data).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. results normalize features\n",
    "np.round(scaled[:5],6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. results normalize features\n",
    "lineplot_matplotlib1(\n",
    "  x1=dataset[\"Date\"], y1=scaled, label1=\"Close Price\",\n",
    "  title=\"Results of Normalize Data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. process inverse normalize features\n",
    "def inverse(scaler, scaled):\n",
    "  hasil = scaler.inverse_transform(scaled.reshape(-1,1))\n",
    "  return hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. process splitting data\n",
    "train_data, test_data = train_test_split(scaled, train_size=0.80, test_size=0.20, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. results splitting data\n",
    "lineplot_matplotlib2(\n",
    "  x1=dataset.iloc[0:len(train_data),0], y1=train_data, label1=\"Training data\",\n",
    "  x2=dataset.iloc[len(train_data):len(dataset),0], y2=test_data, label2=\"Testing data\",\n",
    "  title=\"Results of Splitting Data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for supervised learning\n",
    "def create_dataset(look_back, dataset):\n",
    "    \n",
    "  # declare variable X and Y\n",
    "  dataX = []\n",
    "  dataY = []\n",
    "  \n",
    "  # for loop for create supervised learning\n",
    "  for i in range(look_back, len(dataset)):\n",
    "    dataX.append(dataset[i-look_back:i, 0])\n",
    "    dataY.append(dataset[i, 0])\n",
    "      \n",
    "  # return value X and Y\n",
    "  return np.array(dataX), np.array(dataY)\n",
    "# ----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process supervised learning\n",
    "x_train, y_train = create_dataset(60, train_data)\n",
    "x_test, y_test = create_dataset(60, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Algorithms SBi-LSTM-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config algorithms\n",
    "algorithms=\"SBi-LSTM-RNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process predict with LSTM\n",
    "lstm_model = get_models(algorithms=algorithms, timestep=x_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process predict with LSTM\n",
    "lstm_history, lstm_predictions = get_predictions(\n",
    "  model=lstm_model,\n",
    "  x_train=x_train, y_train=y_train,\n",
    "  x_test=x_test, y_test=y_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results training and validation \n",
    "lineplot_matplotlib1(\n",
    "  x1=lstm_history.epoch, y1=lstm_history.history[\"loss\"], label1=\"loss func on training\",\n",
    "  title=\"Results training and validation on \"+algorithms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse scaler predictions\n",
    "y_test = inverse(scaler, y_test)\n",
    "lstm_predictions = inverse(scaler, lstm_predictions)\n",
    "\n",
    "# results predict with LSTM\n",
    "lineplot_matplotlib3(\n",
    "  x1=dataset[\"Date\"].iloc[len(y_train)+120:].values, y1=y_test, label1=\"actual data\",\n",
    "  x2=dataset[\"Date\"].iloc[len(y_train)+120:].values, y2=lstm_predictions, label2=\"results predictions\",\n",
    "  title=\"Results of Predictions BTC-USD with \"+algorithms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate eror\n",
    "lstm_r, lstm_p, lstm_mae, lstm_rmse, lstm_mape = evaluate_models(y_test, lstm_predictions)\n",
    "\n",
    "# show eror\n",
    "print(\"Evaluate Models with : \"+str(algorithms))\n",
    "print(\"-------------------------------\")\n",
    "print(\"R       : \"+str(lstm_r))\n",
    "print(\"P-value : \"+str(lstm_p))\n",
    "print(\"MAE     : \"+str(lstm_mae))\n",
    "print(\"RMSE    : \"+str(lstm_rmse))\n",
    "print(\"MAPE    : \"+str(lstm_mape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Algorithms SBi-GRU-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config algorithms\n",
    "algorithms=\"SBi-GRU-RNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process predict with GRU\n",
    "gru_model = get_models(algorithms=algorithms, timestep=x_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process predict with GRU\n",
    "gru_history, gru_predictions = get_predictions(\n",
    "  model=gru_model,\n",
    "  x_train=x_train, y_train=y_train,\n",
    "  x_test=x_test, y_test=y_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results training and validation \n",
    "lineplot_matplotlib1(\n",
    "  x1=gru_history.epoch, y1=gru_history.history[\"loss\"], label1=\"loss func on training\",\n",
    "  title=\"Results training and validation on \"+algorithms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse scaler predictions\n",
    "y_test = inverse(scaler, y_test)\n",
    "gru_predictions = inverse(scaler, gru_predictions)\n",
    "\n",
    "# results predict with GRU\n",
    "lineplot_matplotlib3(\n",
    "  x1=dataset[\"Date\"].iloc[len(y_train)+120:].values, y1=y_test, label1=\"actual data\",\n",
    "  x2=dataset[\"Date\"].iloc[len(y_train)+120:].values, y2=gru_predictions, label2=\"results predictions\",\n",
    "  title=\"Results of Predictions BTC-USD with \"+algorithms\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate eror\n",
    "gru_r, gru_p, gru_mae, gru_rmse, gru_mape = evaluate_models(y_test, gru_predictions)\n",
    "\n",
    "# show eror\n",
    "print(\"Evaluate Models with : \"+str(algorithms))\n",
    "print(\"-------------------------------\")\n",
    "print(\"R       : \"+str(gru_r))\n",
    "print(\"P-value : \"+str(gru_p))\n",
    "print(\"MAE     : \"+str(gru_mae))\n",
    "print(\"RMSE    : \"+str(gru_rmse))\n",
    "print(\"MAPE    : \"+str(gru_mape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
